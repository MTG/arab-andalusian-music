{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Docx to Tsv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook concerns the conversion of the word documents with the sanai lyrics into tsv format. It is the first of 3 steps of the transliteration pipeline. The expected format of the input word documents must be strictly adhered to for the entire transliteration process to run smoothly. Please be sure to install all third party libraries used in the imports."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import docx\n",
    "import csv, os\n",
    "from io import StringIO\n",
    "import sys, getopt\n",
    "import argparse\n",
    "\n",
    "from os import listdir, getcwd\n",
    "from os.path import isfile, isdir, join\n",
    "\n",
    "from docx.api import Document"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Expected Format\n",
    "1. Each table would typically contain a single lyrics form, which could be a sanaa, inshad, mawal, or other. \n",
    "\n",
    "2. A table should not have more than one sanaa/inshad/mawal. There should be no grouping whether the contents are of the same form or a different form.\n",
    "\n",
    "3. Cells of each table should not be merged. All rows of the table should have the same number of columns without any form of merging.\n",
    "\n",
    "4. This conversion script assumes four types of cells:\n",
    "\n",
    "    a. Title Cell: which is present in the first row of every table. This would typically contain a dot separated list of identifiers or keywords that characterize the contents of the table. \n",
    "    \n",
    "    b. Section Metadata: In some cases, the cell after the title cell contains metadata information rather than actual lyrics. They would usually indicate instrumental interludes.\n",
    "    \n",
    "    c. Multiline Sanaa: usually a single line of lyrics would be divided into 1 or more line sections. So, each of these line sections would be in its own table column. In cases where multiple poem lines are grouped in one row, line sections corresponding to different lines would be put in the same cell.\n",
    "    \n",
    "    d. Singleline Sanaa: cases where contents of each line are placed on their own row.\n",
    "    \n",
    "    \n",
    "5. The first column of each table is reserved for timing related information. It should only have values on the same rows where there are lyrics information or metadata information (i.e all cells other than title cells). If this timing information was not found or is missing, the first column should be kept empty, but never deleted.\n",
    "\n",
    "6. Empty columns are ignored. \n",
    "\n",
    "7. Each table has at least one row, the title row. Cases where it was useful to only have the title row of a sanaa was when it is known that a sanaa is sung at a given location, but the lyrics contents were not detected. In those cases, the title mentions that it is a sanaa, and has the keyword 'مجهول', meanuning unidentified.\n",
    "\n",
    "8. First row should have text in only one column, as the search will move to the next row once it finishes processing the first row it finds with text. \n",
    "    \n",
    "The following diagram clarifies shows an example of a table corresponding to a multiline sanaa. \n",
    "![title](img/multiline_table.png)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reload(sys)\n",
    "#sys.setdefaultencoding('utf-8') #quick hack to get past python encoding issues for now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#parser info\n",
    "\n",
    "#returns a dictionary of arrays with as many columns were found with meaningful data. works when several lines are in the same cell or when each cell only has one line\n",
    "#it assumes that at least within a row, the number of columns with meaningful data will be the same"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_cell(cell): #types: 1: title cell, 2: section metadata, 3: multiline sanaa, 4: singleline sanaa    \n",
    "        keywords_type1 = [\"موال\",\"إنشاد\", \"الصنعة\"] #keywords that allow us to distinguish a cell as a title cell\n",
    "        keywords_type2 = [\"توشية\"]                  #keywords that allow us to distinguish a cell as a section metadata cell\n",
    "\n",
    "        cell_type = -1\n",
    "        for k in keywords_type1:\n",
    "                if k in cell.text:\n",
    "                        cell_type = 1\n",
    "        for k in keywords_type2:\n",
    "                if k in cell.text:\n",
    "                        cell_type = 2\n",
    "        lines = cell.text.replace('\"', '').strip().split('\\n')\n",
    "        lines = [l.strip() for l in lines]\n",
    "\n",
    "        reduced_lines = []\n",
    "        for l in lines:\n",
    "                if l != '' and l != '\\t' and l != ' ':\n",
    "                        reduced_lines.append(l)\n",
    "        lines = reduced_lines\n",
    "\n",
    "        if type == -1:\n",
    "                if len(lines) == 1:\n",
    "                        cell_type = 4\n",
    "                else:\n",
    "                        cell_type = 3\n",
    "        return cell_type, lines         #will never return -1 as all paths lead to an assignment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_row(row): #return the rows as lists, each representing contents of a tsv row, such that caller function can just keep appendingthe results\n",
    "        row_type = 4  #row_type corresponds to cell type. all is assumed to be singleline. the lowest numbers\n",
    "        row_cells = []\n",
    "\n",
    "        for cell in row.cells:\n",
    "                cell_type, cell_lines = process_cell(cell)\n",
    "                #print(\"cell_type {} \".format(cell_type))\n",
    "                if cell_type < row_type:\n",
    "                        row_type = cell_type\n",
    "                row_cells.append(cell_lines)\n",
    "\n",
    "        #at this point there are n arrays depending on how many relevant columns there were\n",
    "        #they should be parallel arrays, so go over each array and form separate tsv rows\n",
    "\n",
    "        #if ! title row, the first column should be reserved for numbers even if empty\n",
    "        row_lines= []\n",
    "        #find longest, only relevant for type 3 rows (multiline sanaas)\n",
    "        longest = max(len(col) for col in row_cells)\n",
    "        for i in range(0, longest):\n",
    "                tsv_string = StringIO()\n",
    "                tsv_writer = csv.writer(tsv_string, delimiter='\\t')\n",
    "                line_sections = []\n",
    "                for col, rc in enumerate(row_cells):\n",
    "                        if row_type != 1: #if not title row\n",
    "                                if col == 0: #if we are in the first col\n",
    "                                        if len(rc) >= i+1: #if there is a numeric entry\n",
    "                                                line_sections.append(rc[i]) #insert it normally\n",
    "                                        else:                           #if there isn't\n",
    "                                                line_sections.append('')    #still keep the column empty\n",
    "                                else:\n",
    "                                        if len(rc) >= i+1:\n",
    "                                                line_sections.append(rc[i])\n",
    "                        else:\n",
    "                                if len(rc) >= i+1:\n",
    "                                        line_sections.append(rc[i])\n",
    "                tsv_writer.writerow(line_sections)\n",
    "                row_lines.append(tsv_string.getvalue())\n",
    "\n",
    "        if row_type != 1 and row_type != 2:\n",
    "                row_lines.append('\\r\\n') #empty line to divide all different classed rows. the lack of handling for last one rids us of the need to add an empty line before a title row\n",
    "        return  row_type, row_lines\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_sanaa(sanaa): #table is a table object according to the python-docx api\n",
    "        #sanaa_string = StringIO.StringIO()\n",
    "        #sanaa_writer = csv.writer(sanaa_string)\n",
    "\n",
    "        sanaa_string = \"\"\n",
    "        for i, row in enumerate(sanaa.rows):\n",
    "                row_type, lines = process_row(row)\n",
    "                #DEBUG:\n",
    "                #print (\"Lines in ROW: {}\".format(len(lines)))\n",
    "                for l in lines:\n",
    "                        sanaa_string+=l\n",
    "        return sanaa_string\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_document(doc_path):\n",
    "        tsv = \"\"\n",
    "        doc = Document(doc_path)\n",
    "        for table in doc.tables:\n",
    "                tsv += process_sanaa(table)\n",
    "        return tsv\n",
    "\n",
    "#nawba_folders = [fo for fo in listdir(path) if isdir(join(path, fo))]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Usage: Choosing Input Files\n",
    "Select whether the source is a single file or a full folder. In both cases, the tsv versions will be written to the same directory.\n",
    "if a folder is given, it is up to the user to ensure that all files inside adhere to the structure.\n",
    "\n",
    "A small number of .docx examples are given along with those notebooks for demonstration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "isfile = True #True when file, False when folder. \n",
    "              \n",
    "filepath = 'docx_files/3fb6107c-13be-4006-851a-a857ed2f80bb.docx'\n",
    "folderpath = 'docx_files/'\n",
    "\n",
    "path = os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 files in queue\n",
      "docx_files/3fb6107c-13be-4006-851a-a857ed2f80bb.tsv\n",
      "Finished Processing Files\n"
     ]
    }
   ],
   "source": [
    "file_queue = []\n",
    "if isfile:\n",
    "    if os.path.isfile(filepath):\n",
    "        file_queue.append(filepath)\n",
    "else:\n",
    "    if os.path.isdir(folderpath):\n",
    "        file_queue = [fi for fi in listdir(folder) if isfile(join(path, fi))]\n",
    "\n",
    "print(\"{} files in queue\".format(len(file_queue)))\n",
    "\n",
    "for file in file_queue:\n",
    "    tsv = process_document(file)\n",
    "    tsv = tsv.replace(',', '')\n",
    "    tsv = tsv.replace('\"', '')\n",
    "    with open(file[:-4] + 'tsv', 'w') as fileout:\n",
    "        print(file[:-4] + 'tsv')\n",
    "        fileout.write(tsv)        \n",
    "\n",
    "print(\"Finished Processing Files\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
