{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transliteration of tsvs with the Sanaas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the second of 3 notebooks regarding the transliteration of the Arab Andalusian Lyrics. It uses the tsv formt output by the first notebook. Special terms which we would like to bypass from the transliteration script should be placed in special_terms.csv.\n",
    "Note that, in case the romanization of the Arab Andalusian Corpus Lyrics is updated, then the keywords part of the JSON conversion function might need to be updated.\n",
    "\n",
    "The tsv file with the lyrics of a recording are in a single tsv titled with the mbid of the recording. The transliterate_recording function is what handles issues relating to the structure of the recording. transliterate_text just calls the entry point to the transliteration module, and load_special_terms is a utility function to load terms we wish to use predetermined transliterations for rather than transliterate them with the tool. Such cases are only checked for the titles of sanai. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'ArabicTransliterator'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-d357ef713a53>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0misfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0misdir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjoin\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mArabicTransliterator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mArabicTransliterator\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mALA_LC_Transliterator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmishkal\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtashkeel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtashkeel\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtashkeel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'ArabicTransliterator'"
     ]
    }
   ],
   "source": [
    "import sys, os, glob, codecs\n",
    "import csv, os\n",
    "\n",
    "from os import listdir, getcwd\n",
    "from os.path import isfile, isdir, join\n",
    "\n",
    "import ArabicTransliterator\n",
    "from ArabicTransliterator import ALA_LC_Transliterator\n",
    "import mishkal.tashkeel.tashkeel as tashkeel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "transliterator = ALA_LC_Transliterator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transliterate_text(text, vocalize=True):\n",
    "    voc = text\n",
    "    if vocalize:\n",
    "        vocalizer=tashkeel.TashkeelClass()\n",
    "        voc = vocalizer.tashkeel(text)\n",
    "    return transliterator.do(voc.strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_special_terms():\n",
    "    f = codecs.open(\"special_terms.csv\", \"r\", \"utf-8\")\n",
    "    special_terms = {}\n",
    "    for line in f:\n",
    "        data = line.strip().split(\",\") #changed it from csv to tsv\n",
    "        special_terms[data[1]] = data[2]\n",
    "    f.close()\n",
    "    return special_terms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The transliterate_recording function checks if the row being processed is a title row or a regular row. A title row is dot separated with keywords identifying the lyrics form that follows. A regular row should have at least 2 tab separated columns, with the first either being numeric or empty, and the latter being text in arabic script. The function reads from the input file buffer directly, and writes to the output file buffer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def strip_digits(s):\n",
    "        return ''.join([i for i in s if not i.isdigit()])\n",
    "    \n",
    "def transliterate_recording(inbuf, outbuf):\n",
    "    recording_sanas = []\n",
    "    special_terms = load_special_terms()\n",
    "    for line in inbuf:\n",
    "        data = line.strip('\\n').strip('\\r\\n').split('\\t')\n",
    "        if len(data) == 1: #Transliterate san'a title\n",
    "            if len(data[0]) > 0:\n",
    "                text = strip_digits(data[0]).strip().replace(u\"\\u0640\", u\".\")\n",
    "                transliterated_data = []\n",
    "                for elem in text.split(\".\"):\n",
    "                    transliterated_data.append(transliterate_text(elem.strip()))\n",
    "                transliterated_data = u\". \".join(transliterated_data)\n",
    "                for k,v in special_terms.items():\n",
    "                    transliterated_data = transliterated_data.replace(k, v)\n",
    "                outbuf.write(transliterated_data+\"\\n\")\n",
    "            else:\n",
    "                outbuf.write(line)\n",
    "        else: # Transliterate san'a text\n",
    "            i = 0\n",
    "            if data[i].isdigit() == True:\n",
    "                transliterated_data = [data[i]]\n",
    "                i += 1\n",
    "            else:\n",
    "                transliterated_data = []\n",
    "\n",
    "            for elem in data[i:]:\n",
    "                transliterated_data.append(transliterate_text(elem.strip(), vocalize=True))\n",
    "            outbuf.write(\"\\t\".join(transliterated_data)+\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Usage: Choosing Input Files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Select whether the source is a single file or a full folder. In both cases, the transliterated tsvs will be written to the same output directory.\n",
    "if a folder is given, it is up to the user to ensure that all files inside adhere to the structure.\n",
    "\n",
    "In order to fit into the 3 step pipeline given in these notebooks, the locations of the input files and folders are in the locations of notebook 1's output. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "isfile = False #True when file, False when folder. \n",
    "              \n",
    "filepath = 'tsv_files/original/3fb6107c-13be-4006-851a-a857ed2f80bb.tsv'\n",
    "folderpath = 'tsv_files/original/'\n",
    "\n",
    "outputdir = './tsv_files/transliterated/'\n",
    "\n",
    "path = os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 files in queue\n",
      "./tsv_files/transliterated/3fb6107c-13be-4006-851a-a857ed2f80bb.tsv\n",
      "./tsv_files/transliterated/70c04adf-b886-4d62-a88a-abdde5d93715.tsv\n",
      "Finished Processing Files\n"
     ]
    }
   ],
   "source": [
    "file_queue = []\n",
    "\n",
    "if not os.path.isdir(outputdir):\n",
    "    os.makedirs(outputdir)\n",
    "\n",
    "if isfile:\n",
    "    if os.path.isfile(filepath):\n",
    "        file_queue.append(filepath)\n",
    "else:\n",
    "    if os.path.isdir(folderpath):\n",
    "        file_queue = [os.path.join(folderpath, fi) for fi in listdir(folderpath) if fi[-4:] == \".tsv\"]\n",
    "\n",
    "print(\"{} files in queue\".format(len(file_queue)))\n",
    "\n",
    "for file in file_queue:\n",
    "    mbid = file[file.rfind(\"/\")+1:file.rfind(\".\")]\n",
    "    fin = codecs.open(file, \"r\", \"utf-8\")\n",
    "    fout = open(os.path.join(outputdir, \"%s.tsv\" % (mbid)), \"w+\")\n",
    "    \n",
    "    print(os.path.join(outputdir, \"%s.tsv\" % (mbid)))\n",
    "    transliterate_recording(fin, fout)\n",
    "    \n",
    "    fin.close()\n",
    "    fout.close()\n",
    "   \n",
    "\n",
    "print(\"Finished Processing Files\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
